# üè° Optimizaci√≥n de Predicci√≥n de Precios: California Housing

Este proyecto explora la evoluci√≥n de un modelo predictivo, desde una Regresi√≥n Lineal simple hasta un modelo Polin√≥mico Regularizado, aplicando t√©cnicas avanzadas de Machine Learning para controlar el Underfitting y Overfitting.

## üéØ Objetivo
Predecir el precio medio de viviendas en distritos de California, minimizando el Error Cuadr√°tico Medio (MSE) y maximizando la varianza explicada ($R^2$).

## üõ†Ô∏è Tecnolog√≠as y Conceptos Clave
* **Python** (Pandas, NumPy, Matplotlib, Seaborn)
* **Scikit-Learn** (Pipelines, Preprocessing)
* **Ridge Regression**: Para manejar la multicolinealidad y penalizar coeficientes complejos.
* **Polynomial Features**: Para capturar relaciones no lineales en los datos.
* **Grid Search CV**: Para la optimizaci√≥n sistem√°tica de hiperpar√°metros ($\alpha$).

## üìä Evoluci√≥n del Modelo

| Modelo | $R^2$ Score | MSE | Diagn√≥stico |
| :--- | :---: | :---: | :--- |
| **Lineal Simple** | 0.6302 | 0.4937 | **Underfitting**: El modelo era demasiado simple para capturar la realidad del mercado. |
| **Polin√≥mico (Grado 2)** | 0.6102 | 0.5205 | **Overfitting**: No era el objetivo ya que el modelo memoriz√≥ el ruido y fall√≥ en validaci√≥n. |
| **Polin√≥mico + Ridge ($\alpha=100$)** | 0.6941 | 0.4084 | **Optimizado**: Equilibrio ideal entre sesgo y varianza. |
| **Polynomial Features + Log-Transform** | **0.7090** | **0.3886** | **Best Fit**: Manejo de la asimetr√≠a en la variable precio. |

## üöÄ Observaciones 
1.  **Diagn√≥stico de Errores**: Identificar cu√°ndo un modelo es "demasiado simple" vs "demasiado complejo".
2.  **El Poder de Ridge**: C√≥mo el hiperpar√°metro Alpha act√∫a como una "un metodo control" para domar modelos polin√≥micos inestables.
3.  **Grid Search**: La importancia de no adivinar los par√°metros, sino probarlos sistem√°ticamente con Validaci√≥n Cruzada.

## üìà Resultado Final
La gr√°fica compara el desempe√±o inicial del modelo lineal (l√≠nea azul) frente al modelo polin√≥mico optimizado (l√≠nea verde), evidenciando una mejora del ~10% en la precisi√≥n.
<img width="1149" height="633" alt="image" src="https://github.com/user-attachments/assets/42706414-d954-4a37-b1e3-07364493a393" />

Exprimiendo lo maximo que se puede sacar con Log Transform
<img width="588" height="134" alt="image" src="https://github.com/user-attachments/assets/328255e6-f87f-4b61-af65-f778434ff164" />
